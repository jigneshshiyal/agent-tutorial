{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee06ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee74a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add_num(a:int, b:int) -> int:\n",
    "    \"\"\"\n",
    "        add two number\n",
    "        a: number a\n",
    "        b: number b\n",
    "        return sum of two number \n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274f441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_num.invoke({\"a\":3, \"b\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369baff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_nodes = ToolNode([add_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7cba10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = [{\"name\": \"add_num\", \"args\": {\"a\": 5, \"b\": 3}, \"id\": \"1\", \"type\": \"tool_call\"}]\n",
    "result = tool_nodes.invoke(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56fe74e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='8', name='add_num', tool_call_id='1')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07011f",
   "metadata": {},
   "source": [
    "### call tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b4eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", api_key=GEMINI_API_KEY)\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[add_num]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "624ad1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='add 2 and 8', additional_kwargs={}, response_metadata={}, id='9a10beb8-b660-47f4-982c-85c474733de2'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'add_num', 'arguments': '{\"b\": 8.0, \"a\": 2.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--2f5e0baa-938d-4675-8758-7974a2d32438-0', tool_calls=[{'name': 'add_num', 'args': {'b': 8.0, 'a': 2.0}, 'id': '7b3eb7ea-94b5-4059-a576-5ae932c6fa21', 'type': 'tool_call'}], usage_metadata={'input_tokens': 72, 'output_tokens': 89, 'total_tokens': 161, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 69}}),\n",
       "  ToolMessage(content='10', name='add_num', id='8fd634f8-09b8-4aed-9fce-eec143c0189c', tool_call_id='7b3eb7ea-94b5-4059-a576-5ae932c6fa21'),\n",
       "  AIMessage(content='The sum of 2 and 8 is 10.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--03a78421-047e-47d1-8014-c74af3f8afaa-0', usage_metadata={'input_tokens': 108, 'output_tokens': 13, 'total_tokens': 121, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\":\"add 2 and 8\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92eda3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools([add_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4716ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = model_with_tools.invoke(\"add 5 and 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90d3f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = response_message.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6028bb08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='11', name='add_num', tool_call_id='c6b62162-9595-484e-8329-4ce7df3ac51a')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_num.invoke(tool_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabd8fef",
   "metadata": {},
   "source": [
    "### Tool Customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d193d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter descriptions\n",
    "# Explicit input schema\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TempCustomSchema(BaseModel):\n",
    "    a:int = Field(description=\"First operand\")\n",
    "    b:int = Field(description=\"Second operand\")\n",
    "\n",
    "@tool(\"add_nums\", args_schema=TempCustomSchema)\n",
    "def add_num(a:int, b:int) -> int:\n",
    "    \"\"\"\n",
    "        add two numer\n",
    "        a: number\n",
    "        b: number\n",
    "        return sum of numbers\n",
    "    \"\"\"\n",
    "    return a+b "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f9b1c",
   "metadata": {},
   "source": [
    "### Context Management "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad345a15",
   "metadata": {},
   "source": [
    "#### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c36725f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "@tool(\"add_num\")\n",
    "def add_num(a:int, b:int, config:RunnableConfig)-> int:\n",
    "    \"\"\"\"add two number\n",
    "\n",
    "    Args:\n",
    "        a: number\n",
    "        b: number\n",
    "    \"\"\"\n",
    "    print(config[\"configurable\"].get(\"sample\", \"blank\"))\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d9ceec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_nodes = ToolNode([add_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b6bffb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='8', name='add_num', tool_call_id='1')]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls = [{\"name\": \"add_num\", \"args\": {\"a\": 5, \"b\": 3}, \"id\": \"1\", \"type\": \"tool_call\"}]\n",
    "\n",
    "tool_nodes.invoke(tool_calls, config={\"configurable\": {\"sample\": \"user_123\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478a730",
   "metadata": {},
   "source": [
    "#### short-term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4dd1c6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
    "from typing import Annotated, NotRequired\n",
    "from langgraph.prebuilt import InjectedState, create_react_agent\n",
    "\n",
    "class CustomState(AgentState):\n",
    "    user_name: NotRequired[str]\n",
    "\n",
    "@tool\n",
    "def get_user_name(\n",
    "    state: Annotated[CustomState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"Retrieve the current user-name from state.\"\"\"\n",
    "    # Return stored name or a default if not set\n",
    "    return state.get(\"user_name\", \"Unknown user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30e820cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[get_user_name],\n",
    "    state_schema=CustomState\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a9bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='b9d0f8f2-060b-47a1-8d01-df778ce5b431'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_user_name', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--f8027f1f-1bd7-4082-bdf8-8502f37ef264-0', tool_calls=[{'name': 'get_user_name', 'args': {}, 'id': '27b4db6c-498e-4cdd-ac99-768b5b859e89', 'type': 'tool_call'}], usage_metadata={'input_tokens': 39, 'output_tokens': 57, 'total_tokens': 96, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 45}}),\n",
       "  ToolMessage(content='Unknown user', name='get_user_name', id='85a8cf50-a823-4d62-8a7c-717021dc5e9b', tool_call_id='27b4db6c-498e-4cdd-ac99-768b5b859e89'),\n",
       "  AIMessage(content=\"I don't know your name.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--8d4565f7-ed27-4a6c-8b00-b82abd6ea278-0', usage_metadata={'input_tokens': 69, 'output_tokens': 8, 'total_tokens': 77, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\": \"what's my name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f67386a",
   "metadata": {},
   "source": [
    "#### long-term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdb3b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.config import get_store\n",
    "\n",
    "@tool\n",
    "def get_user_info(config: RunnableConfig) -> str:\n",
    "    \"\"\"Look up user info.\"\"\"\n",
    "    # Same as that provided to `builder.compile(store=store)`\n",
    "    # or `create_react_agent`\n",
    "    store = get_store()\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    user_info = store.get((\"users\",), user_id)\n",
    "    return str(user_info.value) if user_info else \"Unknown user\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037c9c2",
   "metadata": {},
   "source": [
    "#### Tool features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b50df30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# immediate result\n",
    "@tool(return_direct=True)\n",
    "def add_num(a:int, b:int):\n",
    "    \"\"\"add two numbers\n",
    "    Args:\n",
    "        a: int number\n",
    "        b: int number\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8aa4523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# force tool to use\n",
    "@tool(return_direct=True)\n",
    "def greet(user_name: str) -> int:\n",
    "    \"\"\"Greet user.\"\"\"\n",
    "    return f\"Hello {user_name}!\"\n",
    "\n",
    "tools = [greet]\n",
    "\n",
    "configured_model = model.bind_tools(\n",
    "    tools,\n",
    "    # Force the use of the 'greet' tool\n",
    "    tool_choice={\"type\": \"tool\", \"name\": \"greet\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20086286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000002010B566850>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'greet', 'description': 'Greet user.', 'parameters': {'properties': {'user_name': {'type': 'string'}}, 'required': ['user_name'], 'type': 'object'}}}], 'parallel_tool_calls': False}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# disable parallel call\n",
    "model.bind_tools(\n",
    "    tools,\n",
    "    parallel_tool_calls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a8539c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content=\"Error: ValueError('The ultimate error')\\n Please fix your mistakes.\", name='multiply', tool_call_id='tool_call_id', status='error')]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handle error\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"multiply two numbers\n",
    "\n",
    "    Args:\n",
    "        a: integer number\n",
    "        b: integer number\n",
    "    \"\"\"\n",
    "    if a == 42:\n",
    "        raise ValueError(\"The ultimate error\")\n",
    "    return a * b\n",
    "\n",
    "# Default error handling (enabled by default)\n",
    "tool_node = ToolNode([multiply])\n",
    "\n",
    "message = AIMessage(\n",
    "    content=\"\",\n",
    "    tool_calls=[{\n",
    "        \"name\": \"multiply\",\n",
    "        \"args\": {\"a\": 42, \"b\": 7},\n",
    "        \"id\": \"tool_call_id\",\n",
    "        \"type\": \"tool_call\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "result = tool_node.invoke({\"messages\": [message]})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48793aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable error handling \n",
    "# tool_node = ToolNode([multiply], handle_tool_errors=False)\n",
    "# result = tool_node.invoke({\"messages\": [message]})\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3d322ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content=\"Can't use 42 as the first operand, please switch operands!\", name='multiply', tool_call_id='tool_call_id', status='error')]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom error messages\n",
    "tool_node = ToolNode(\n",
    "    [multiply],\n",
    "    handle_tool_errors=\"Can't use 42 as the first operand, please switch operands!\"\n",
    ")\n",
    "\n",
    "result = tool_node.invoke({\"messages\": [message]})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753bb9fc",
   "metadata": {},
   "source": [
    "#### prebuild tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c9a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ed23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc70c35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb9492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef8428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac5347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568da1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5190c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd444f20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42ebf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
