{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8c6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistent execution state\n",
    "# dynamic interrupts\n",
    "# static interrupts\n",
    "# flexible integration points\n",
    "\n",
    "# pattern \n",
    "# approve or reject\n",
    "# edit graph state\n",
    "# review tool call\n",
    "# validate human input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc87c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed25082",
   "metadata": {},
   "source": [
    "### pause using intrrupt and Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce87e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "import uuid\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "class State(TypedDict):\n",
    "    some_text: str\n",
    "\n",
    "\n",
    "def human_node(state: State):\n",
    "    value = interrupt(  \n",
    "        {\n",
    "            \"text_to_revise\": state[\"some_text\"]  \n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"some_text\": value  \n",
    "    }\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"human_node\", human_node)\n",
    "graph_builder.add_edge(START, \"human_node\")\n",
    "checkpointer = InMemorySaver()  \n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "result = graph.invoke({\"some_text\": \"original text\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03366d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'some_text': 'Edited text asd'}\n"
     ]
    }
   ],
   "source": [
    "print(graph.invoke(Command(resume=\"Edited text asd\"), config=config)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf65f5",
   "metadata": {},
   "source": [
    "### Resume multiple interrupts with one invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4444517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    text_1: str\n",
    "    text_2: str\n",
    "\n",
    "def node_1(state: CustomState):\n",
    "    value = interrupt({\"text_to_revise\": state[\"text_1\"]})\n",
    "    return {\"text_1\": value}\n",
    "\n",
    "def node_2(state: CustomState):\n",
    "    value = interrupt({\"text_to_revise\": state[\"text_2\"]})\n",
    "    return {\"text_2\": value}\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(CustomState)\n",
    "    .add_node(\"node_1\", node_1)\n",
    "    .add_node(\"node_2\", node_2)\n",
    "    .add_edge(START, \"node_1\")\n",
    "    .add_edge(START, \"node_2\")\n",
    "    .compile(checkpointer=checkpointer)\n",
    ")\n",
    "\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a8c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = workflow.invoke({\"text_1\":\"sample 1\", \"text_2\":\"sample 2\"}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c567e620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Interrupt(value={'text_to_revise': 'sample 1'}, resumable=True, ns=['node_1:02cc6dd3-0ff9-4323-a2c0-cd5fcc489234']),\n",
       " Interrupt(value={'text_to_revise': 'sample 2'}, resumable=True, ns=['node_2:4016d254-115b-d0b7-3849-f0e7a0a231ef']))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config).interrupts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e309c248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bce26acd4a2e361e4a32b1997bec4e99': 'human input for prompt sample 1',\n",
       " '170065d56cfa3c5ce7d67c5baf60fdd1': 'human input for prompt sample 2'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_map = {\n",
    "    i.interrupt_id: f\"human input for prompt {i.value[\"text_to_revise\"]}\"\n",
    "    for i in workflow.get_state(config).interrupts\n",
    "}\n",
    "\n",
    "resume_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d671e906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_1': 'human input for prompt sample 1', 'text_2': 'human input for prompt sample 2'}\n"
     ]
    }
   ],
   "source": [
    "print(workflow.invoke(Command(resume=resume_map), config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac0e03",
   "metadata": {},
   "source": [
    "### Comman Pattern "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ac1a7",
   "metadata": {},
   "source": [
    "#### Approve and reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a06ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '61887ee0-f0b8-42c0-b580-aec3912718f3'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.types import interrupt, Command\n",
    "import uuid\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    llm_output: str\n",
    "    decision: str\n",
    "\n",
    "def generate_llm_output(state: CustomState) -> CustomState:\n",
    "    return {\"llm_output\": state[\"llm_output\"]}\n",
    "\n",
    "def human_approval(state: CustomState) -> Command[Literal[\"approved_path\", \"rejected_path\"]]:\n",
    "    decision = interrupt({\n",
    "        \"question\": \"Do you approve the following output?\",\n",
    "        \"llm_output\": state[\"llm_output\"]\n",
    "    })\n",
    "\n",
    "    if decision == \"approve\":\n",
    "        return Command(goto=\"approved_path\", update={\"decision\": \"approve\"})\n",
    "    else:\n",
    "        return Command(goto=\"rejected_path\", update={\"decision\": \"reject\"})\n",
    "    \n",
    "def approved_path(state: CustomState) -> CustomState:\n",
    "    print(f\"Approve node : {state[\"decision\"]}\")\n",
    "    return state\n",
    "        \n",
    "def rejected_path(state: CustomState) -> CustomState:\n",
    "    print(f\"Reject node : {state[\"decision\"]}\")\n",
    "    return state\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(CustomState)\n",
    "    .add_node(\"generate_llm_output\", generate_llm_output)\n",
    "    .add_node(\"human_approval\", human_approval)\n",
    "    .add_node(\"approved_path\", approved_path)\n",
    "    .add_node(\"rejected_path\", rejected_path)\n",
    "    .add_edge(START, \"generate_llm_output\")\n",
    "    .add_edge(\"generate_llm_output\", \"human_approval\")\n",
    "    .add_edge(\"approved_path\", END)\n",
    "    .add_edge(\"rejected_path\", END)\n",
    "    .compile(checkpointer=checkpoint)\n",
    ")\n",
    "\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76dcd3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm_output': 'hello',\n",
       " '__interrupt__': [Interrupt(value={'question': 'Do you approve the following output?', 'llm_output': 'hello'}, resumable=True, ns=['human_approval:df80d458-a392-0b04-a0fa-7bc311a15b1c'])]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = workflow.invoke({\"llm_output\":\"hello\"}, config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ca944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approve node : approve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_output': 'hello', 'decision': 'approve'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = workflow.invoke(Command(resume=\"approve\"), config=config)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dbd30f",
   "metadata": {},
   "source": [
    "#### Review and edit state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031722f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '6f331fb0-20cd-400b-ba24-4b250e67e588'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Literal, TypedDict\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    llm_output: str\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "\n",
    "def generate_llm_output(state: CustomState) -> CustomState:\n",
    "    return {\"llm_output\": state[\"llm_output\"]}\n",
    "\n",
    "def human_edit_node(state: CustomState) -> CustomState:\n",
    "    response = interrupt({\n",
    "        \"request\": \"make simple edit\",\n",
    "        \"llm_generate_output\": state[\"llm_output\"]\n",
    "    })\n",
    "\n",
    "    return {\n",
    "        \"llm_output\": response[\"change_output\"]\n",
    "    }\n",
    "\n",
    "def checking_node(state: CustomState) -> CustomState:\n",
    "    print(f\"Check Change Output: {state['llm_output']}\")\n",
    "    return state\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(CustomState)\n",
    "    .add_node(\"generate_llm_output\", generate_llm_output)\n",
    "    .add_node(\"human_edit_node\", human_edit_node)\n",
    "    .add_node(\"checking_node\", checking_node)\n",
    "    .set_entry_point(\"generate_llm_output\")\n",
    "    .add_edge(\"generate_llm_output\", \"human_edit_node\")\n",
    "    .add_edge(\"human_edit_node\", \"checking_node\")\n",
    "    .compile(checkpointer=checkpoint)\n",
    ")\n",
    "\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364d59ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm_output': 'demo llm output',\n",
       " '__interrupt__': [Interrupt(value={'request': 'make simple edit', 'llm_generate_output': 'demo llm output'}, resumable=True, ns=['human_edit_node:d49cdce0-36c7-33d8-0f55-0448e83c689e'])]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respose = workflow.invoke({\"llm_output\": \"demo llm output\"}, config=config)\n",
    "respose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251cc846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check Change Output: llm output is change\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'llm_output': 'llm output is change'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_edit = workflow.invoke(Command(resume={\"change_output\": \"llm output is change\"}), config=config)\n",
    "final_edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27df1a3",
   "metadata": {},
   "source": [
    "#### Review Tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97203e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': 'fa943d44-ec2a-4305-8eaf-a07337f6242e'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", api_key=GEMINI_API_KEY)\n",
    "\n",
    "def check_hotel_name(hotel_name: str):\n",
    "    \"\"\"check hotel name\n",
    "\n",
    "    Args:\n",
    "        hotel_name: name of hotel\n",
    "    \"\"\"\n",
    "    response = interrupt({\n",
    "        f\"Call hotel_name function with {hotel_name}, edit or approve\"\n",
    "    })\n",
    "\n",
    "    if response[\"type\"] == \"edit\":\n",
    "        hotel_name = response[\"args\"][\"hotel_name\"]\n",
    "    elif response[\"type\"] == \"accept\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown response type: {response['type']}\")\n",
    "    \n",
    "    return f\"Successfully booked a stay at {hotel_name}.\"\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[check_hotel_name],\n",
    "    checkpointer=checkpoint\n",
    ")\n",
    "\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00422746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='book a stay at McKittrick hotel', additional_kwargs={}, response_metadata={}, id='172c5200-b00f-4e2f-94ce-54e561674403'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'check_hotel_name', 'arguments': '{\"hotel_name\": \"McKittrick hotel\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4f8eb1f6-20b5-4caa-a92c-6870e29f12d1-0', tool_calls=[{'name': 'check_hotel_name', 'args': {'hotel_name': 'McKittrick hotel'}, 'id': '8268c3dd-cd66-4d8a-888e-5844ff603b20', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 88, 'total_tokens': 151, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 66}})],\n",
       " '__interrupt__': [Interrupt(value={'Call hotel_name function with McKittrick hotel, edit or approve'}, resumable=True, ns=['tools:4dd86363-32f5-9d24-d93b-b58eb8e686c3'])]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"book a stay at McKittrick hotel\"}]},config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "339902b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='book a stay at McKittrick hotel', additional_kwargs={}, response_metadata={}, id='172c5200-b00f-4e2f-94ce-54e561674403'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'check_hotel_name', 'arguments': '{\"hotel_name\": \"McKittrick hotel\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4f8eb1f6-20b5-4caa-a92c-6870e29f12d1-0', tool_calls=[{'name': 'check_hotel_name', 'args': {'hotel_name': 'McKittrick hotel'}, 'id': '8268c3dd-cd66-4d8a-888e-5844ff603b20', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 88, 'total_tokens': 151, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 66}}),\n",
       "  ToolMessage(content='Successfully booked a stay at creditt.', name='check_hotel_name', id='56d72cbe-6df2-48e5-b2bf-b206493333b0', tool_call_id='8268c3dd-cd66-4d8a-888e-5844ff603b20'),\n",
       "  AIMessage(content=\"I'm sorry, I cannot fulfill this request. The McKittrick Hotel is not a real hotel and therefore I cannot book a stay there. \", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--59796c51-6b73-45ef-b18f-5b5c9b6888ce-0', usage_metadata={'input_tokens': 109, 'output_tokens': 30, 'total_tokens': 139, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = agent.invoke(Command(resume={\"type\":\"accept\"}),config=config)\n",
    "response = agent.invoke(Command(resume={\"type\":\"edit\", \"args\":{\"hotel_name\":\"creditt\"}}),config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd33203",
   "metadata": {},
   "source": [
    "#### Add interrupt to any tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6380762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add interrupt to any tool\n",
    "from typing import Callable\n",
    "from langchain_core.tools import BaseTool, tool as create_tool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.prebuilt.interrupt import HumanInterruptConfig, HumanInterrupt\n",
    "\n",
    "def add_human_in_loop(tool: Callable | BaseTool, *, interrupt_config: HumanInterruptConfig = None) -> BaseTool:\n",
    "    \"\"\"Wrap a tool to support human-in-the-loop review.\"\"\"\n",
    "    if not isinstance(tool, BaseTool):\n",
    "        tool = create_tool(tool)\n",
    "\n",
    "    if interrupt_config == None:\n",
    "        interrupt_config ={\n",
    "            \"allow_accept\": True,\n",
    "            \"allow_edit\": True,\n",
    "            \"allow_respond\": True\n",
    "        }\n",
    "\n",
    "    @create_tool(tool.name, description=tool.description, args_schema=tool.args_schema)\n",
    "    def call_tool_with_interrupt(config: RunnableConfig, **tool_input):\n",
    "        request: HumanInterrupt = {\n",
    "            \"action_request\" :{\n",
    "                \"action\": tool.name,\n",
    "                \"args\": tool_input\n",
    "            },\n",
    "            \"config\": interrupt_config,\n",
    "            \"description\": \"please review tool call\"\n",
    "        }\n",
    "\n",
    "        response = interrupt([request])[0]\n",
    "\n",
    "        if response[\"type\"] == \"edit\":\n",
    "            print(response)\n",
    "            tool_input = response[\"args\"][\"args\"]\n",
    "            tool_response = tool.invoke(tool_input, config=config)\n",
    "        elif response[\"type\"] == \"accept\":\n",
    "            tool_response = tool.invoke(tool_input, config=config)\n",
    "        elif response[\"type\"] == \"response\":\n",
    "            user_feedback  = response[\"args\"]\n",
    "            tool_response = user_feedback\n",
    "\n",
    "\n",
    "        return tool_response\n",
    "    \n",
    "    return call_tool_with_interrupt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba29a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "\n",
    "def book_hotel(hotel_name: str):\n",
    "   \"\"\"Book a hotel\n",
    "\n",
    "    Args:\n",
    "        hotel_name: name of hotel\n",
    "   \"\"\"\n",
    "   return f\"Successfully booked a stay at {hotel_name}.\"\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\", api_key=GEMINI_API_KEY)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=model,\n",
    "    tools=[add_human_in_loop(book_hotel)],\n",
    "    checkpointer=checkpoint\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8b82741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='book a stay at McKittrick hotel', additional_kwargs={}, response_metadata={}, id='4f9fd17c-7845-424c-bbed-73234e84ef4f'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_hotel', 'arguments': '{\"hotel_name\": \"McKittrick hotel\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4021c750-b090-4da3-8a08-10e87dfe2eab-0', tool_calls=[{'name': 'book_hotel', 'args': {'hotel_name': 'McKittrick hotel'}, 'id': 'fa2fa4cc-02cc-4bf0-ba29-e3fd903295ab', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 95, 'total_tokens': 156, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 75}})],\n",
       " '__interrupt__': [Interrupt(value=[{'action_request': {'action': 'book_hotel', 'args': {'hotel_name': 'McKittrick hotel'}}, 'config': {'allow_accept': True, 'allow_edit': True, 'allow_respond': True}, 'description': 'please review tool call'}], resumable=True, ns=['tools:c00105d2-746e-c940-8545-3127fe821e2d'])]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"book a stay at McKittrick hotel\"}]},config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "515a9d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='book a stay at McKittrick hotel', additional_kwargs={}, response_metadata={}, id='4f9fd17c-7845-424c-bbed-73234e84ef4f'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'book_hotel', 'arguments': '{\"hotel_name\": \"McKittrick hotel\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--4021c750-b090-4da3-8a08-10e87dfe2eab-0', tool_calls=[{'name': 'book_hotel', 'args': {'hotel_name': 'McKittrick hotel'}, 'id': 'fa2fa4cc-02cc-4bf0-ba29-e3fd903295ab', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 95, 'total_tokens': 156, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 75}}),\n",
       "  ToolMessage(content='Error: KeyError(0)\\n Please fix your mistakes.', name='book_hotel', id='c682778a-9328-45a3-be9e-91b7e41942c8', tool_call_id='fa2fa4cc-02cc-4bf0-ba29-e3fd903295ab', status='error'),\n",
       "  AIMessage(content='I am unable to book a stay at the McKittrick hotel. Please try again.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--6fc99c6e-9ff4-4c33-91ca-6491c97a4536-0', usage_metadata={'input_tokens': 107, 'output_tokens': 18, 'total_tokens': 125, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent.invoke(Command(resume={\"type\":\"accept\"}),config=config)\n",
    "# response = agent.invoke(Command(resume={\"type\":\"edit\", \"args\":{\"hotel_name\":\"creditt++++\"}}),config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26911836",
   "metadata": {},
   "source": [
    "#### Validate human input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ceafc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '2cf8c7d5-6015-4dc0-b0d2-335d9357274d'}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.types import interrupt, Command\n",
    "import uuid\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import Literal, TypedDict\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "    age: int\n",
    "\n",
    "def get_validate_age(state: CustomState) -> CustomState:\n",
    "    prompt = \"please enter youar age(must be integer)\"\n",
    "\n",
    "    while True:\n",
    "        user_input = interrupt(prompt)\n",
    "\n",
    "        try:\n",
    "            age = int(user_input)\n",
    "            if age < 0:\n",
    "                raise ValueError(\"age is negative, enter positive integer\")\n",
    "            break\n",
    "        except (ValueError, TypeError):\n",
    "            prompt = f\"'{user_input}' is not valid. Please enter a non-negative integer for age.\"\n",
    "\n",
    "    return {'age': age}\n",
    "\n",
    "def report_age(state: CustomState) -> CustomState:\n",
    "    print(f\"✅ Human is {state['age']} years old.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(CustomState)\n",
    "    .add_node(\"get_validate_age\", get_validate_age)\n",
    "    .add_node(\"report_age\", report_age)\n",
    "    .set_entry_point(\"get_validate_age\")\n",
    "    .add_edge(\"get_validate_age\", \"report_age\")\n",
    "    .add_edge(\"report_age\", END)\n",
    "    .compile(checkpointer=checkpoint)\n",
    ")\n",
    "\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7938945a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__interrupt__': [Interrupt(value='please enter youar age(must be integer)', resumable=True, ns=['get_validate_age:7fdb63b4-a400-e6f8-f590-afdbd600fb01'])]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = workflow.invoke({}, config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a26917eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__interrupt__': [Interrupt(value=\"'not a number' is not valid. Please enter a non-negative integer for age.\", resumable=True, ns=['get_validate_age:7fdb63b4-a400-e6f8-f590-afdbd600fb01'])]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = workflow.invoke(Command(resume=\"not a number\"), config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "257dedb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__interrupt__': [Interrupt(value=\"'-1' is not valid. Please enter a non-negative integer for age.\", resumable=True, ns=['get_validate_age:7fdb63b4-a400-e6f8-f590-afdbd600fb01'])]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = workflow.invoke(Command(resume=\"-1\"), config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7e7133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Human is 5 years old.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = workflow.invoke(Command(resume=\"5\"), config=config)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6852af",
   "metadata": {},
   "source": [
    "#### Debug with interrupts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55ac05db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '872b255a-469d-436e-b2e8-f93f21fb2519'}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.types import interrupt, Command\n",
    "from langgraph.constants import START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpoint = InMemorySaver()\n",
    "\n",
    "def step_1(state: MessagesState) -> MessagesState:\n",
    "    return {\"messages\":f\"hello world, {state[\"messages\"]}\"}\n",
    "\n",
    "def step_2(state: MessagesState) -> MessagesState:\n",
    "    print(\"Node 2\")\n",
    "    return {\"messages\": f\"node 2 is execute\"}\n",
    "\n",
    "def step_3(state: MessagesState) -> MessagesState:\n",
    "    print(\"Node 3\")\n",
    "    return {\"messages\": f\"node 3 is execute\"}\n",
    "\n",
    "workflow = (\n",
    "    StateGraph(MessagesState)\n",
    "    .add_node(\"step_1\", step_1)\n",
    "    .add_node(\"step_2\", step_2)\n",
    "    .add_node(\"step_3\", step_3)\n",
    "    .set_entry_point(\"step_1\")\n",
    "    .add_edge(\"step_1\", \"step_2\")\n",
    "    .add_edge(\"step_2\", \"step_3\")\n",
    "    .add_edge(\"step_3\", END)\n",
    "    .compile(\n",
    "        checkpointer=checkpoint,\n",
    "        interrupt_after=[\"step_1\"],\n",
    "        interrupt_before=[\"step_2\", \"step_3\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "import uuid\n",
    "\n",
    "config = {\n",
    "    \"configurable\":{\n",
    "        \"thread_id\": str(uuid.uuid4())\n",
    "    }\n",
    "}\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8feef61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='b7257382-acc5-4c1b-9d8a-d5cf4c10c757'),\n",
       "  HumanMessage(content=\"hello world, [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='b7257382-acc5-4c1b-9d8a-d5cf4c10c757')]\", additional_kwargs={}, response_metadata={}, id='9ec67c74-5c19-4bd4-a350-c0ed845802a1')]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = workflow.invoke({\"messages\": \"hello\"}, config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24112cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='b7257382-acc5-4c1b-9d8a-d5cf4c10c757'),\n",
       "  HumanMessage(content=\"hello world, [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='b7257382-acc5-4c1b-9d8a-d5cf4c10c757')]\", additional_kwargs={}, response_metadata={}, id='9ec67c74-5c19-4bd4-a350-c0ed845802a1'),\n",
       "  HumanMessage(content='node 2 is execute', additional_kwargs={}, response_metadata={}, id='1f7d01c5-72fa-483c-99e9-3f2f19724121')]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = workflow.invoke(None, config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fef6d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='b7257382-acc5-4c1b-9d8a-d5cf4c10c757'),\n",
       "  HumanMessage(content=\"hello world, [HumanMessage(content='hello', additional_kwargs={}, response_metadata={}, id='b7257382-acc5-4c1b-9d8a-d5cf4c10c757')]\", additional_kwargs={}, response_metadata={}, id='9ec67c74-5c19-4bd4-a350-c0ed845802a1'),\n",
       "  HumanMessage(content='node 2 is execute', additional_kwargs={}, response_metadata={}, id='1f7d01c5-72fa-483c-99e9-3f2f19724121'),\n",
       "  HumanMessage(content='node 3 is execute', additional_kwargs={}, response_metadata={}, id='3423d24a-dd0b-495d-babd-840ec5f36e43')]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = workflow.invoke(None, config=config)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce635aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considerations \n",
    "# 1. side effect, call api or execute function after inttrupt or make new node \n",
    "# 2. when subgraph have intrrupts then parent graph execute from interrupt or subgraph called node\n",
    "# 3. mulitple inttrupts in single node"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
